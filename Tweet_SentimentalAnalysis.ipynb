{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa3095ef",
   "metadata": {},
   "source": [
    "# Assignment project 6 : Sentiment analysis on 1.6 million tweets.\n",
    "This is the sentiment140 dataset. It contains 1,600,000 tweets extracted using the twitter api . The tweets have been annotated (0 = negative, 4 = positive) and they can be used to detect sentiment.\n",
    "\n",
    "It contains the following 6 fields:\n",
    "\n",
    "target: the polarity of the tweet (0 = negative, 2 = neutral, 4 = positive)\n",
    "\n",
    "ids: The id of the tweet ( 2087)\n",
    "\n",
    "date: the date of the tweet (Sat May 16 23:58:44 UTC 2009)\n",
    "\n",
    "flag: The query (lyx). If there is no query, then this value is NO_QUERY. user: the user that tweeted (robotickilldozr)\n",
    "\n",
    "text: the text of the tweet (Lyx is cool)\n",
    "\n",
    "Dataset link : https://www.kaggle.com/kazanova/sentiment140"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef79f214",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets first import all the neccessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re           # re= regular expression\n",
    "import string\n",
    "\n",
    "# methods and stop words text processing\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a6b346",
   "metadata": {},
   "source": [
    "# English stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "717b4fdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Manjula\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " 'if',\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  creating a stopwords set and store them to a variable \n",
    "nltk.download('stopwords')\n",
    "stop_words= set(stopwords.words('english') )\n",
    "stop_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a11e3ab",
   "metadata": {},
   "source": [
    "# Load the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ffef0c3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0           1                             2         3                4  \\\n",
       "0  0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY  _TheSpecialOne_   \n",
       "1  0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY    scotthamilton   \n",
       "2  0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY         mattycus   \n",
       "3  0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY          ElleCTF   \n",
       "4  0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY           Karoli   \n",
       "\n",
       "                                                   5  \n",
       "0  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
       "1  is upset that he can't update his Facebook by ...  \n",
       "2  @Kenichan I dived many times for the ball. Man...  \n",
       "3    my whole body feels itchy and like its on fire   \n",
       "4  @nationwideclass no, it's not behaving at all....  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reading dataset \n",
    "tweet_df= pd.read_csv('training.1600000.processed.noemoticon.csv', encoding= 'latin1',header= None )\n",
    "tweet_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1888aa2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1600000, 6)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2749f4dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 4], dtype=int64)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_df[0].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "dae17c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_df.drop(columns= [1,2,3,4], axis=1, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0cb53bbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Label                                             Tweets\n",
       "0      0  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
       "1      0  is upset that he can't update his Facebook by ...\n",
       "2      0  @Kenichan I dived many times for the ball. Man...\n",
       "3      0    my whole body feels itchy and like its on fire \n",
       "4      0  @nationwideclass no, it's not behaving at all...."
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_df.columns= ['Label', 'Tweets']\n",
    "tweet_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "11834a01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1600000 entries, 0 to 1599999\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count    Dtype \n",
      "---  ------  --------------    ----- \n",
      " 0   Label   1600000 non-null  int64 \n",
      " 1   Tweets  1600000 non-null  object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 24.4+ MB\n"
     ]
    }
   ],
   "source": [
    "tweet_df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "12f62fef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    800000\n",
       "4    800000\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_df.Label.value_counts()              # here we have 80k negative and 80 postive tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7b3ee6aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1600000"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tweet_df)                  # this is too much of data and im not sure if my machine will be able to process it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fced6f49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800000 800000\n"
     ]
    }
   ],
   "source": [
    "# i will first segregate the positive and negative tweets \n",
    "df_pos= tweet_df[tweet_df['Label'] == 4]\n",
    "df_neg= tweet_df[tweet_df['Label'] == 0]\n",
    "print(len(df_pos), len(df_neg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0eb87fc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 10000\n"
     ]
    }
   ],
   "source": [
    "# Only retaining 1/8th of our data from each output group coz im unsure about my machines power\n",
    "df_pos = df_pos.iloc[:int(len(df_pos)/80)]\n",
    "df_neg = df_neg.iloc[:int(len(df_neg)/80)]\n",
    "print(len(df_pos), len(df_neg))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7b0124ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20000"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concate both positive and negative tweets and store tehm back to one df\n",
    "tweet_df1= pd.concat([df_pos, df_neg])\n",
    "len(tweet_df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "36f87d37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>800000</th>\n",
       "      <td>4</td>\n",
       "      <td>I LOVE @Health4UandPets u guys r the best!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800001</th>\n",
       "      <td>4</td>\n",
       "      <td>im meeting up with one of my besties tonight! ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Label                                             Tweets\n",
       "800000      4       I LOVE @Health4UandPets u guys r the best!! \n",
       "800001      4  im meeting up with one of my besties tonight! ..."
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_df1.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "248c79f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  lets first separate our features and labels to x, y\n",
    "x= tweet_df1['Tweets'].to_list()       # to_list will get teh text in list and not in df \n",
    "y= tweet_df1['Label'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d44b495b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['I LOVE @Health4UandPets u guys r the best!! ',\n",
       "  'im meeting up with one of my besties tonight! Cant wait!!  - GIRL TALK!!',\n",
       "  '@DaRealSunisaKim Thanks for the Twitter add, Sunisa! I got to meet you once at a HIN show here in the DC area and you were a sweetheart. ',\n",
       "  'Being sick can be really cheap when it hurts too much to eat real food  Plus, your friends make you soup',\n",
       "  '@LovesBrooklyn2 he has that effect on everyone '],\n",
       " [4, 4, 4, 4, 4])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:5], y[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea72f38a",
   "metadata": {},
   "source": [
    "# Preprocessing the Tweet text \n",
    "1. Casing - handeling conversion of uppercase/lowercase\n",
    "2. Noise Removal - unwanted charectors such as htmltags, punctuation marks, special char,white space etc\n",
    "3. Tokenization - to convert all texts/tweets into tokens(all tokens would be words separated by spaces   \n",
    "4. Stopwords removal - some words don't contribute much to ML model so remove them(they dont contain any important significance)\n",
    "5. Text Normalization (Stemming/lemmatization)- this is based on stemming and lemmatization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d6051fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# writing a function for preprocessing\n",
    "\n",
    "def preprocess_tweet_text(tweet):\n",
    "    #convert all text to lower case\n",
    "    tweet= tweet.lower()\n",
    "    \n",
    "    #remove any urls\n",
    "    tweet= re.sub(r\"www\\S+ |http\\S+ |https\\S+\", \"\", tweet, flags=re.MULTILINE)\n",
    "    \n",
    "    #remove user @ reference and # from the tweet\n",
    "    tweet= re.sub(r\"\\@\\w+ |\\#\", \"\", tweet)\n",
    "    \n",
    "    #remove punctuations\n",
    "    tweet= tweet.translate(str.maketrans(\"\", \"\", string.punctuation))  # translate method will create a mapping table for punctuations with space\n",
    "    \n",
    "    #remove stopwords ; before removing stopwords we need to convert tweets to tokens\n",
    "    tweet_tokens= word_tokenize(tweet)\n",
    "    filterted_words= [word for word in tweet_tokens if word not in stop_words]\n",
    "    \n",
    "    #stemming \n",
    "    ps= PorterStemmer()\n",
    "    stemmed_words= [ps.stem(word) for word in filterted_words]\n",
    "    \n",
    "    #lemmatizing \n",
    "    lammatizer= WordNetLemmatizer()\n",
    "    lemma_words= [lammatizer.lemmatize(word, pos= 'a') for word in stemmed_words]\n",
    "    \n",
    "    return \" \".join(lemma_words)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "cf6191c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hi arti prepar mock interview'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the preprocessing is done lets see how the example works on it\n",
    "preprocess_tweet_text(\"Hi arti, how are you preparing for mock interview?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f5670a73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'im meeting up with one of my besties tonight! Cant wait!!  - GIRL TALK!!'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "26ba6403",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'im meet one besti tonight cant wait girl talk'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_tweet_text(x[1])            # This is what i get after preprocess is done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1bc91f91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Tweets</th>\n",
       "      <th>Cleaned_tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>800000</th>\n",
       "      <td>4</td>\n",
       "      <td>I LOVE @Health4UandPets u guys r the best!!</td>\n",
       "      <td>love u guy r best</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800001</th>\n",
       "      <td>4</td>\n",
       "      <td>im meeting up with one of my besties tonight! ...</td>\n",
       "      <td>im meet one besti tonight cant wait girl talk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800002</th>\n",
       "      <td>4</td>\n",
       "      <td>@DaRealSunisaKim Thanks for the Twitter add, S...</td>\n",
       "      <td>thank twitter add sunisa got meet hin show dc ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800003</th>\n",
       "      <td>4</td>\n",
       "      <td>Being sick can be really cheap when it hurts t...</td>\n",
       "      <td>sick realli cheap hurt much eat real food plu ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800004</th>\n",
       "      <td>4</td>\n",
       "      <td>@LovesBrooklyn2 he has that effect on everyone</td>\n",
       "      <td>effect everyon</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Label                                             Tweets  \\\n",
       "800000      4       I LOVE @Health4UandPets u guys r the best!!    \n",
       "800001      4  im meeting up with one of my besties tonight! ...   \n",
       "800002      4  @DaRealSunisaKim Thanks for the Twitter add, S...   \n",
       "800003      4  Being sick can be really cheap when it hurts t...   \n",
       "800004      4    @LovesBrooklyn2 he has that effect on everyone    \n",
       "\n",
       "                                           Cleaned_tweets  \n",
       "800000                                  love u guy r best  \n",
       "800001      im meet one besti tonight cant wait girl talk  \n",
       "800002  thank twitter add sunisa got meet hin show dc ...  \n",
       "800003  sick realli cheap hurt much eat real food plu ...  \n",
       "800004                                     effect everyon  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_df1['Cleaned_tweets']= tweet_df1['Tweets'].apply(preprocess_tweet_text)\n",
    "\n",
    "# show the cleaned text \n",
    "tweet_df1.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8faab140",
   "metadata": {},
   "source": [
    "# Vectorization Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "24cbe952",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<20000x19375 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 141234 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we need to convert the tokens to vectors coz machine can only read num data\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv=CountVectorizer()\n",
    "text_counts=cv.fit_transform(tweet_df1['Cleaned_tweets'])\n",
    "text_counts\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7d3f4538",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x19375 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 3 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# text_counts[0].toarray()            # to_array will give the matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "74e1a10e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    10000\n",
       "0    10000\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_df1['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d50d4ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "42d37f01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "800000    1\n",
       "800001    1\n",
       "800002    1\n",
       "800003    1\n",
       "800004    1\n",
       "         ..\n",
       "9995      0\n",
       "9996      0\n",
       "9997      0\n",
       "9998      0\n",
       "9999      0\n",
       "Name: Label, Length: 20000, dtype: int64"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# here X will be the features we extracted using vectorization\n",
    "\n",
    "X= text_counts\n",
    "Y= tweet_df1['Label']\n",
    "\n",
    "Y=Y.map({0:0,4:1})                    # mapping 0-> 0 (negative), 4-> 1 (positive)\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "2639f935",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    10000\n",
       "0    10000\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d1a1acdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets split X and Y using train test split. \n",
    "\n",
    "x_train, x_test, y_train, y_test= train_test_split(X, Y, test_size=0.2, random_state=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "dd25842c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train[:5], y_train[:5]         # just to compare the train and its result/target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "2a90bdd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<5x19375 sparse matrix of type '<class 'numpy.int64'>'\n",
       " \twith 42 stored elements in Compressed Sparse Row format>,\n",
       " 807808    1\n",
       " 804702    1\n",
       " 808693    1\n",
       " 809085    1\n",
       " 6689      0\n",
       " Name: Label, dtype: int64)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test[:5], y_test[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41ccc4b",
   "metadata": {},
   "source": [
    "# Model Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "9ee2f02e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=2, random_state=0)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "# traning \n",
    "model= RandomForestClassifier(n_estimators=100, max_depth=2, random_state=0)\n",
    "model.fit(x_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "fdfe3b74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6880072137060416"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing \n",
    "y_pred= model.predict(x_test)\n",
    "f1_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "315e91a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.654"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets check accuracy score\n",
    "accuracy_score(y_test, y_pred)         \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "ee061fd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[0]  # this is positive tweet  ; 0-negative, 1-postive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "bcdc4f75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[100]  # this is negative tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "65fc16c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 0, 1, 0, 0, 0, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[:10] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "d04b7aa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "807808    1\n",
       "804702    1\n",
       "808693    1\n",
       "809085    1\n",
       "6689      0\n",
       "4093      0\n",
       "2799      0\n",
       "809439    1\n",
       "7783      0\n",
       "933       0\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b027d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note- I have just taken very small amount of data for minimizing the computational power. \n",
    "# One can use the entire dataset to and train it to increase the accuracy; can even chose a differnt \n",
    "# classifier algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d5000a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venvDL1",
   "language": "python",
   "name": "venvdl1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
